{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f8f76b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T22:12:48.163332Z",
     "start_time": "2022-12-07T22:12:46.576398Z"
    }
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.optimize import  least_squares\n",
    "\n",
    "!wget https://raw.githubusercontent.com/rpazuki/MLCourse/main/utils.py\n",
    "from utils import *\n",
    "\n",
    "\n",
    "np.random.seed(43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f0ea2",
   "metadata": {},
   "source": [
    "# Fitting the fluorescent intensity data by a Hill function\n",
    "\n",
    "> In this notebook, we will see how we can use the __Least square__ package from the __scipy.optimize__ to fit on a synthesis dataset.\n",
    "> Remember that in this case, the family of all Hill function is our __hypothesis space__. So, we need to select a function by determining _activation coefficient_, $K$, and _Hill coefficient_, $n$.\n",
    "\n",
    "> In the follwoing cell, we first plot the Hill function for different parameters. Notice the effect of changing $K$ and $n$ on the resulting plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e690d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:40:34.802102Z",
     "start_time": "2022-12-07T19:40:34.594970Z"
    }
   },
   "outputs": [],
   "source": [
    "def Hill(x, K, n):\n",
    "    \"\"\"Hill function for gene expression rate\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "       x: concentration\n",
    "       K: activation coefficient\n",
    "       n: Hill coefficient\n",
    "       \n",
    "    Return: float or ndarray\n",
    "       The fluorescent intensity\n",
    "    \"\"\"\n",
    "    return 1.0/(1.0 + (K/(x + 1e-20))**n )\n",
    "\n",
    "def plot_Hill(ax, xs, Ks, ns):\n",
    "    for K, n in zip(Ks, ns):\n",
    "        ax.plot(xs, Hill(xs, K, n), label=f\"K={K}, n={n}\")        \n",
    "    plot_Hill_general(ax)\n",
    "    \n",
    "xs = np.linspace(0,3)\n",
    "_ = plt.figure(figsize=(12,4))\n",
    "ax = plt.subplot(121)\n",
    "plot_Hill(ax, xs, [1, 1, 1], [2, 4, 8])\n",
    "ax = plt.subplot(122)\n",
    "plot_Hill(ax, xs, [1, 2, 3], [4, 4, 4])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4d326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:11:52.504225Z",
     "start_time": "2022-12-07T19:11:52.497280Z"
    }
   },
   "source": [
    "> We plot the same dataset that we used in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7f17b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:40:37.473086Z",
     "start_time": "2022-12-07T19:40:37.352875Z"
    }
   },
   "outputs": [],
   "source": [
    "xs = np.linspace(0.0, 3, num=18)[2:]\n",
    "ys = Hill(xs, 1.0, 4) + np.random.normal(0.0, .04, xs.shape)\n",
    "\n",
    "_ = plt.figure(figsize=(6,4))\n",
    "ax = plt.gca()\n",
    "ax.scatter(xs, ys, c='r', marker='o', label=\"Measurment\")   \n",
    "plot_Hill_general(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6087e",
   "metadata": {},
   "source": [
    "> Next, we divide the data (xs, ys) to _train_ and _test_ sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3a673907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:40:58.260917Z",
     "start_time": "2022-12-07T19:40:58.255000Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = train_test(xs, ys, train_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a60efa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:41:01.313323Z",
     "start_time": "2022-12-07T19:41:01.186178Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(8,4))\n",
    "ax = plt.gca()\n",
    "ax.scatter(x_train, y_train, c='r', marker='o', label=\"Train data\")   \n",
    "ax.scatter(x_test, y_test, c='b', marker='x', label=\"Test data\")   \n",
    "plot_Hill_general(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be4f61",
   "metadata": {},
   "source": [
    "> Remember to select a Hill function, the algorithem must search the __parametes__ using __data__.\n",
    "> To do it, we can create a function that its first argument is $K$ and $n$, while the remainings are x and y. > The function calculates the deviation by subtracting the observed _y_ from its estimated _Hill(x, K, n)_.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "55d31b95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T20:07:55.124802Z",
     "start_time": "2022-12-07T20:07:55.118801Z"
    }
   },
   "outputs": [],
   "source": [
    "def deviation(coefficients, xs, ys):\n",
    "    K, n = coefficients\n",
    "    return ys - Hill(xs, K, n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f206f7",
   "metadata": {},
   "source": [
    "> __scipy.optimize__ library impliments the least square, in  __least_squares__ function. It takes the deviation function, initial guess, and arguments. In our case, we use [K=1, n=1] as initial guess, and x_train and y_train as arguments. Recall that the __Data__ is the argument and parameters our uknown.\n",
    "\n",
    "> The estimated $K$ and $n$ are returen in the output of the __least_squares__ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d5d3ab90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T20:11:44.146877Z",
     "start_time": "2022-12-07T20:11:44.133188Z"
    }
   },
   "outputs": [],
   "source": [
    "result = least_squares(deviation, [1, 1], args=(x_train, y_train))\n",
    "estimated_K, estimated_n = result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e226ffa",
   "metadata": {},
   "source": [
    "# Practice 1:\n",
    "\n",
    "print the __result__ variable to see its content. Where can we find more information about __least_squares__ function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb72d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67af3aa8",
   "metadata": {},
   "source": [
    "# Practice 2:\n",
    "\n",
    "Find the $L2$ deviations in their sum for both train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0e19ef07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T20:13:17.694205Z",
     "start_time": "2022-12-07T20:13:17.686605Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_epsilons = deviation((estimated_K, estimated_n), x_train, y_train)\n",
    "#train_L2 = np.sum([epsilon**2 for epsilon in train_epsilons])\n",
    "#test_epsilons = deviation((estimated_K, estimated_n), x_test, y_test)\n",
    "#test_L2 = np.sum([epsilon**2 for epsilon in test_epsilons])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a953d06d",
   "metadata": {},
   "source": [
    "> Finally, we plot the estimated function, using the parameters reslted from __least_squares__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5996ca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T19:57:45.033586Z",
     "start_time": "2022-12-07T19:57:44.877310Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(6,4))\n",
    "ax = plt.gca()\n",
    "ax.scatter(x_train, y_train, c='r', marker='o', label=\"Measurment\") \n",
    "ax.plot(x_train, \n",
    "        Hill(x_train, estimated_K, estimated_n), \n",
    "        label=f\"K={estimated_K:.2f}, n={estimated_n:.2f}\")\n",
    "plt.title(f\"Train L2={train_L2:.3f}, Test L2={test_L2:.4f}\", fontsize=16)\n",
    "for x,y in zip(x_train, y_train):\n",
    "    ax.plot([x,x], [y, Hill(x, estimated_K, estimated_n)], 'g--')\n",
    "plot_Hill_general(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeda089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
